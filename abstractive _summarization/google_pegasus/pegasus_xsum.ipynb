{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adbd4ae1",
   "metadata": {},
   "source": [
    "## 0. Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a68bc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/lts/1.8/cpu\n",
      "Requirement already satisfied: torch==1.8.2 in c:\\users\\shahin\\anaconda3\\lib\\site-packages (1.8.2+cu111)\n",
      "Requirement already satisfied: torchvision==0.9.2 in c:\\users\\shahin\\anaconda3\\lib\\site-packages (0.9.2+cu111)\n",
      "Requirement already satisfied: torchaudio===0.8.2 in c:\\users\\shahin\\anaconda3\\lib\\site-packages (0.8.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from torch==1.8.2) (1.21.5)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from torch==1.8.2) (4.1.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from torchvision==0.9.2) (9.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.8.2 torchvision==0.9.2 torchaudio===0.8.2 --extra-index-url https://download.pytorch.org/whl/lts/1.8/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38dc3be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\shahin\\anaconda3\\lib\\site-packages (4.19.2)\n",
      "Requirement already satisfied: requests in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.9)\n"
     ]
    }
   ],
   "source": [
    "# Install transformers\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2ac740",
   "metadata": {},
   "source": [
    "# Import and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e8097f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dependencies from transformers\n",
    "from transformers import PegasusForConditionalGeneration\n",
    "# from transformers import PegasusTokenizer\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import torch\n",
    "# PegasusTokenizer requires the SentencePiece library\n",
    "\n",
    "# PegasusTokenizer\n",
    "# tokenizer converts the sentences into a set of tokens\n",
    "# number representation of our sentences rather than passing through the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0900347a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in c:\\users\\shahin\\anaconda3\\lib\\site-packages (0.1.96)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab2d213e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load model \n",
    "model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-xsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1643a408",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ea7f2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\shahin\\anaconda3\\lib\\site-packages (4.19.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from requests->transformers) (2021.10.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7a40a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/pegasus-xsum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4589527",
   "metadata": {},
   "source": [
    "# Perform Abstractive Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5617a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: goose3 in c:\\users\\shahin\\anaconda3\\lib\\site-packages (3.1.11)\n",
      "Requirement already satisfied: nltk in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from goose3) (3.7)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from goose3) (2.8.2)\n",
      "Requirement already satisfied: langdetect in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from goose3) (1.0.9)\n",
      "Requirement already satisfied: lxml in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from goose3) (4.8.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from goose3) (4.11.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from goose3) (9.0.1)\n",
      "Requirement already satisfied: cssselect in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from goose3) (1.1.0)\n",
      "Requirement already satisfied: requests in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from goose3) (2.27.1)\n",
      "Requirement already satisfied: jieba in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from goose3) (0.42.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from beautifulsoup4->goose3) (2.3.1)\n",
      "Requirement already satisfied: six in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from langdetect->goose3) (1.16.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from nltk->goose3) (1.1.0)\n",
      "Requirement already satisfied: click in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from nltk->goose3) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from nltk->goose3) (2022.3.15)\n",
      "Requirement already satisfied: tqdm in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from nltk->goose3) (4.64.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from click->nltk->goose3) (0.4.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from requests->goose3) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from requests->goose3) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from requests->goose3) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\shahin\\anaconda3\\lib\\site-packages (from requests->goose3) (1.26.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install goose3\n",
    "from goose3 import Goose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76513bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Goose() # Goose is the class which will be used to extract the text from the url.\n",
    "url = 'https://www.sciencedaily.com/releases/2021/08/210811162816.htm'\n",
    "article = g.extract(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e16ecf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Global warming begets more warming, new paleoclimate study finds'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1da9697e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta': {'description': \"Global warming begets more, extreme warming, new paleoclimate study finds. Researchers observe a 'warming bias' over the past 66 million years that may return if ice sheets disappear.\",\n",
       "  'lang': 'en',\n",
       "  'keywords': 'Global Warming; Climate; Environmental Issues; Earth Science; Early Climate; Fossils; Origin of Life; Evolution',\n",
       "  'favicon': '',\n",
       "  'canonical': 'https://www.sciencedaily.com/releases/2021/08/210811162816.htm',\n",
       "  'encoding': 'utf-8'},\n",
       " 'image': None,\n",
       " 'domain': 'www.sciencedaily.com',\n",
       " 'title': 'Global warming begets more warming, new paleoclimate study finds',\n",
       " 'cleaned_text': 'It is increasingly clear that the prolonged drought conditions, record-breaking heat, sustained wildfires, and frequent, more extreme storms experienced in recent years are a direct result of rising global temperatures brought on by humans\\' addition of carbon dioxide to the atmosphere. And a new MIT study on extreme climate events in Earth\\'s ancient history suggests that today\\'s planet may become more volatile as it continues to warm.\\n\\nThe study, appearing today in , examines the paleoclimate record of the last 66 million years, during the Cenozoic era, which began shortly after the extinction of the dinosaurs. The scientists found that during this period, fluctuations in the Earth\\'s climate experienced a surprising \"warming bias.\" In other words, there were far more warming events -- periods of prolonged global warming, lasting thousands to tens of thousands of years -- than cooling events. What\\'s more, warming events tended to be more extreme, with greater shifts in temperature, than cooling events.\\n\\nThe researchers say a possible explanation for this warming bias may lie in a \"multiplier effect,\" whereby a modest degree of warming -- for instance from volcanoes releasing carbon dioxide into the atmosphere -- naturally speeds up certain biological and chemical processes that enhance these fluctuations, leading, on average, to still more warming.\\n\\nInterestingly, the team observed that this warming bias disappeared about 5 million years ago, around the time when ice sheets started forming in the Northern Hemisphere. It\\'s unclear what effect the ice has had on the Earth\\'s response to climate shifts. But as today\\'s Arctic ice recedes, the new study suggests that a multiplier effect may kick back in, and the result may be a further amplification of human-induced global warming.\\n\\n\"The Northern Hemisphere\\'s ice sheets are shrinking, and could potentially disappear as a long-term consequence of human actions\" says the study\\'s lead author Constantin Arnscheidt, a graduate student in MIT\\'s Department of Earth, Atmospheric and Planetary Sciences. \"Our research suggests that this may make the Earth\\'s climate fundamentally more susceptible to extreme, long-term global warming events such as those seen in the geologic past.\"\\n\\nArnscheidt\\'s study co-author is Daniel Rothman, professor of geophysics at MIT, and co-founder and co-director of MIT\\'s Lorenz Center.\\n\\nFor their analysis, the team consulted large databases of sediments containing deep-sea benthic foraminifera -- single-celled organisms that have been around for hundreds of millions of years and whose hard shells are preserved in sediments. The composition of these shells is affected by the ocean temperatures as organisms are growing; the shells are therefore considered a reliable proxy for the Earth\\'s ancient temperatures.\\n\\nFor decades, scientists have analyzed the composition of these shells, collected from all over the world and dated to various time periods, to track how the Earth\\'s temperature has fluctuated over millions of years.\\n\\n\"When using these data to study extreme climate events, most studies have focused on individual large spikes in temperature, typically of a few degrees Celsius warming,\" Arnscheidt says. \"Instead, we tried to look at the overall statistics and consider all the fluctuations involved, rather than picking out the big ones.\"\\n\\nThe team first carried out a statistical analysis of the data and observed that, over the last 66 million years, the distribution of global temperature fluctuations didn\\'t resemble a standard bell curve, with symmetric tails representing an equal probability of extreme warm and extreme cool fluctuations. Instead, the curve was noticeably lopsided, skewed toward more warm than cool events. The curve also exhibited a noticeably longer tail, representing warm events that were more extreme, or of higher temperature, than the most extreme cold events.\\n\\n\"This indicates there\\'s some sort of amplification relative to what you would otherwise have expected,\" Arnscheidt says. \"Everything\\'s pointing to something fundamental that\\'s causing this push, or bias toward warming events.\"\\n\\n\"It\\'s fair to say that the Earth system becomes more volatile, in a warming sense,\" Rothman adds.\\n\\nThe team wondered whether this warming bias might have been a result of \"multiplicative noise\" in the climate-carbon cycle. Scientists have long understood that higher temperatures, up to a point, tend to speed up biological and chemical processes. Because the carbon cycle, which is a key driver of long-term climate fluctuations, is itself composed of such processes, increases in temperature may lead to larger fluctuations, biasing the system towards extreme warming events.\\n\\nIn mathematics, there exists a set of equations that describes such general amplifying, or multiplicative effects. The researchers applied this multiplicative theory to their analysis to see whether the equations could predict the asymmetrical distribution, including the degree of its skew and the length of its tails.\\n\\nIn the end, they found that the data, and the observed bias toward warming, could be explained by the multiplicative theory. In other words, it\\'s very likely that, over the last 66 million years, periods of modest warming were on average further enhanced by multiplier effects, such as the response of biological and chemical processes that further warmed the planet.\\n\\nAs part of the study, the researchers also looked at the correlation between past warming events and changes in Earth\\'s orbit. Over hundreds of thousands of years, Earth\\'s orbit around the sun regularly becomes more or less elliptical. But scientists have wondered why many past warming events appeared to coincide with these changes, and why these events feature outsized warming compared with what the change in Earth\\'s orbit could have wrought on its own.\\n\\nSo, Arnscheidt and Rothman incorporated the Earth\\'s orbital changes into the multiplicative model and their analysis of Earth\\'s temperature changes, and found that multiplier effects could predictably amplify, on average, the modest temperature rises due to changes in Earth\\'s orbit.\\n\\n\"Climate warms and cools in synchrony with orbital changes, but the orbital cycles themselves would predict only modest changes in climate,\" Rothman says. \"But if we consider a multiplicative model, then modest warming, paired with this multiplier effect, can result in extreme events that tend to occur at the same time as these orbital changes.\"\\n\\n\"Humans are forcing the system in a new way,\" Arnscheidt adds. \"And this study is showing that, when we increase temperature, we\\'re likely going to interact with these natural, amplifying effects.\"\\n\\nThis research was supported, in part, by MIT\\'s School of Science.',\n",
       " 'opengraph': {'title': 'Global warming begets more warming, new paleoclimate study finds',\n",
       "  'type': 'article',\n",
       "  'url': 'https://www.sciencedaily.com/releases/2021/08/210811162816.htm',\n",
       "  'image': 'https://www.sciencedaily.com/images/scidaily-icon.png',\n",
       "  'description': \"Global warming begets more, extreme warming, new paleoclimate study finds. Researchers observe a 'warming bias' over the past 66 million years that may return if ice sheets disappear.\",\n",
       "  'site_name': 'ScienceDaily'},\n",
       " 'tags': ['Evolution',\n",
       "  'Fossils',\n",
       "  'Global Warming',\n",
       "  'Climate',\n",
       "  'Early Climate',\n",
       "  'Earth Science',\n",
       "  'Environmental Issues',\n",
       "  'Origin of Life'],\n",
       " 'tweets': [],\n",
       " 'movies': [],\n",
       " 'links': [],\n",
       " 'authors': [],\n",
       " 'publish_date': None}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article.infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94947907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It is increasingly clear that the prolonged drought conditions, record-breaking heat, sustained wildfires, and frequent, more extreme storms experienced in recent years are a direct result of rising global temperatures brought on by humans\\' addition of carbon dioxide to the atmosphere. And a new MIT study on extreme climate events in Earth\\'s ancient history suggests that today\\'s planet may become more volatile as it continues to warm.\\n\\nThe study, appearing today in , examines the paleoclimate record of the last 66 million years, during the Cenozoic era, which began shortly after the extinction of the dinosaurs. The scientists found that during this period, fluctuations in the Earth\\'s climate experienced a surprising \"warming bias.\" In other words, there were far more warming events -- periods of prolonged global warming, lasting thousands to tens of thousands of years -- than cooling events. What\\'s more, warming events tended to be more extreme, with greater shifts in temperature, than cooling events.\\n\\nThe researchers say a possible explanation for this warming bias may lie in a \"multiplier effect,\" whereby a modest degree of warming -- for instance from volcanoes releasing carbon dioxide into the atmosphere -- naturally speeds up certain biological and chemical processes that enhance these fluctuations, leading, on average, to still more warming.\\n\\nInterestingly, the team observed that this warming bias disappeared about 5 million years ago, around the time when ice sheets started forming in the Northern Hemisphere. It\\'s unclear what effect the ice has had on the Earth\\'s response to climate shifts. But as today\\'s Arctic ice recedes, the new study suggests that a multiplier effect may kick back in, and the result may be a further amplification of human-induced global warming.\\n\\n\"The Northern Hemisphere\\'s ice sheets are shrinking, and could potentially disappear as a long-term consequence of human actions\" says the study\\'s lead author Constantin Arnscheidt, a graduate student in MIT\\'s Department of Earth, Atmospheric and Planetary Sciences. \"Our research suggests that this may make the Earth\\'s climate fundamentally more susceptible to extreme, long-term global warming events such as those seen in the geologic past.\"\\n\\nArnscheidt\\'s study co-author is Daniel Rothman, professor of geophysics at MIT, and co-founder and co-director of MIT\\'s Lorenz Center.\\n\\nFor their analysis, the team consulted large databases of sediments containing deep-sea benthic foraminifera -- single-celled organisms that have been around for hundreds of millions of years and whose hard shells are preserved in sediments. The composition of these shells is affected by the ocean temperatures as organisms are growing; the shells are therefore considered a reliable proxy for the Earth\\'s ancient temperatures.\\n\\nFor decades, scientists have analyzed the composition of these shells, collected from all over the world and dated to various time periods, to track how the Earth\\'s temperature has fluctuated over millions of years.\\n\\n\"When using these data to study extreme climate events, most studies have focused on individual large spikes in temperature, typically of a few degrees Celsius warming,\" Arnscheidt says. \"Instead, we tried to look at the overall statistics and consider all the fluctuations involved, rather than picking out the big ones.\"\\n\\nThe team first carried out a statistical analysis of the data and observed that, over the last 66 million years, the distribution of global temperature fluctuations didn\\'t resemble a standard bell curve, with symmetric tails representing an equal probability of extreme warm and extreme cool fluctuations. Instead, the curve was noticeably lopsided, skewed toward more warm than cool events. The curve also exhibited a noticeably longer tail, representing warm events that were more extreme, or of higher temperature, than the most extreme cold events.\\n\\n\"This indicates there\\'s some sort of amplification relative to what you would otherwise have expected,\" Arnscheidt says. \"Everything\\'s pointing to something fundamental that\\'s causing this push, or bias toward warming events.\"\\n\\n\"It\\'s fair to say that the Earth system becomes more volatile, in a warming sense,\" Rothman adds.\\n\\nThe team wondered whether this warming bias might have been a result of \"multiplicative noise\" in the climate-carbon cycle. Scientists have long understood that higher temperatures, up to a point, tend to speed up biological and chemical processes. Because the carbon cycle, which is a key driver of long-term climate fluctuations, is itself composed of such processes, increases in temperature may lead to larger fluctuations, biasing the system towards extreme warming events.\\n\\nIn mathematics, there exists a set of equations that describes such general amplifying, or multiplicative effects. The researchers applied this multiplicative theory to their analysis to see whether the equations could predict the asymmetrical distribution, including the degree of its skew and the length of its tails.\\n\\nIn the end, they found that the data, and the observed bias toward warming, could be explained by the multiplicative theory. In other words, it\\'s very likely that, over the last 66 million years, periods of modest warming were on average further enhanced by multiplier effects, such as the response of biological and chemical processes that further warmed the planet.\\n\\nAs part of the study, the researchers also looked at the correlation between past warming events and changes in Earth\\'s orbit. Over hundreds of thousands of years, Earth\\'s orbit around the sun regularly becomes more or less elliptical. But scientists have wondered why many past warming events appeared to coincide with these changes, and why these events feature outsized warming compared with what the change in Earth\\'s orbit could have wrought on its own.\\n\\nSo, Arnscheidt and Rothman incorporated the Earth\\'s orbital changes into the multiplicative model and their analysis of Earth\\'s temperature changes, and found that multiplier effects could predictably amplify, on average, the modest temperature rises due to changes in Earth\\'s orbit.\\n\\n\"Climate warms and cools in synchrony with orbital changes, but the orbital cycles themselves would predict only modest changes in climate,\" Rothman says. \"But if we consider a multiplicative model, then modest warming, paired with this multiplier effect, can result in extreme events that tend to occur at the same time as these orbital changes.\"\\n\\n\"Humans are forcing the system in a new way,\" Arnscheidt adds. \"And this study is showing that, when we increase temperature, we\\'re likely going to interact with these natural, amplifying effects.\"\\n\\nThis research was supported, in part, by MIT\\'s School of Science.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article.cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2df6cbe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6770"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(article.cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72f2a44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = article.cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "590e36b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tokens - number representation of our text\n",
    "tokens = tokenizer(text, truncation=True, padding=\"longest\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e323123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  168,   117,  3632,   786,   120,   109, 13488, 11945,  1047,   108,\n",
       "          1093,   121, 13802,  1206,   108,  8123, 39471,   108,   111,  5030,\n",
       "           108,   154,  3837, 11913,  1267,   115,   909,   231,   127,   114,\n",
       "          1443,   711,   113,  4220,  1122,  4374,  1457,   124,   141,  4095,\n",
       "           131,   663,   113,  3359, 13405,   112,   109,  2918,   107,   325,\n",
       "           114,   177, 14842,   692,   124,  3837,  2354,   702,   115,  2774,\n",
       "           131,   116,  3266,   689,  4079,   120,   380,   131,   116,  3909,\n",
       "           218,   460,   154, 16434,   130,   126,  2138,   112,  1515,   107,\n",
       "           139,   692,   108,  8741,   380,   115,   110,   108, 12414,   109,\n",
       "         33375, 47207,  1093,   113,   109,   289,  8449,   604,   231,   108,\n",
       "           333,   109,   597, 17711, 73730,  4065,   108,   162,  1219,  5683,\n",
       "           244,   109, 22526,   113,   109, 23105,   107,   139,  4182,   374,\n",
       "           120,   333,   136,   908,   108, 21044,   115,   109,  2774,   131,\n",
       "           116,  2354,  1267,   114,  5946,   198, 44765,  9983,   496,   222,\n",
       "           176,   989,   108,   186,   195,   571,   154,  8309,   702,  1315,\n",
       "          5059,   113, 13488,  1122,  8309,   108,  4894,  1873,   112, 11371,\n",
       "           113,  1873,   113,   231,  1315,   197,  4814,   702,   107,   463,\n",
       "           131,   116,   154,   108,  8309,   702, 21415,   112,   129,   154,\n",
       "          3837,   108,   122,  1626,  9428,   115,  1972,   108,   197,  4814,\n",
       "           702,   107,   139,  2995,   416,   114,   433,  6024,   118,   136,\n",
       "          8309,  9983,   218,  5372,   115,   114,   198, 24086, 82296,  1298,\n",
       "           745, 15455,   114,  9419,  1393,   113,  8309,  1315,   118,  2468,\n",
       "           135, 31227,  8320,  3359, 13405,   190,   109,  2918,  1315,  3737,\n",
       "          6544,   164,   878,  7777,   111,  3568,  1994,   120,  2541,   219,\n",
       "         21044,   108,   964,   108,   124,  1077,   108,   112,   309,   154,\n",
       "          8309,   107, 21342,   108,   109,   320,  5221,   120,   136,  8309,\n",
       "          9983, 11623,   160,   371,   604,   231,   754,   108,   279,   109,\n",
       "           166,   173,  2003,  4651,   547,  7599,   115,   109,  3701, 35302,\n",
       "           107,   168,   131,   116, 10767,   180,  1298,   109,  2003,   148,\n",
       "           196,   124,   109,  2774,   131,   116,  1407,   112,  2354,  9428,\n",
       "           107,   343,   130,   380,   131,   116, 12546,  2003, 61574,   116,\n",
       "           108,   109,   177,   692,  4079,   120,   114, 33675,  1298,   218,\n",
       "          3951,   247,   115,   108,   111,   109,   711,   218,   129,   114,\n",
       "           701, 41269,   113,   883,   121, 18561,  1122,  8309,   107,   198,\n",
       "           159,  3701, 35302,   131,   116,  2003,  4651,   127, 25044,   108,\n",
       "           111,   256,  3744, 10966,   130,   114,   300,   121,  1704, 10687,\n",
       "           113,   883,  2332,   194,   649,   109,   692,   131,   116,   756,\n",
       "          1782, 80822, 33759, 74407,   144,   108,   114,  3177,   980,   115,\n",
       "         14842,   131,   116,  1318,   113,  2774,   108, 43847,   111, 55278,\n",
       "          5735,   107,   198,   822,   473,  4079,   120,   136,   218,   193,\n",
       "           109,  2774,   131,   116,  2354, 16521,   154, 13400,   112,  3837,\n",
       "           108,   300,   121,  1704,  1122,  8309,   702,   253,   130,   274,\n",
       "           684,   115,   109, 59057,   555,   496, 33759, 74407,   144,   131,\n",
       "           116,   692,  1229,   121, 13873,   117,  4767, 14390,  1121,   108,\n",
       "          4609,   113, 87896,   134, 14842,   108,   111,  1229,   121,  9489,\n",
       "           111,  1229,   121, 22655,   113, 14842,   131,   116, 80187,   900,\n",
       "           107,   321,   153,  1382,   108,   109,   320, 19470,   423,  8669,\n",
       "           113, 45163,  4510,  1355,   121, 13778,   129, 89221,   118,  1524,\n",
       "           386, 46934,  1315,   612,   121, 12052,   316, 14800,   120,   133,\n",
       "           174,   279,   118,  2490,   113,  3734,   113,   231,   111,  1843,\n",
       "           514, 14299,   127, 10303,   115, 45163,   107,   139,  5349,   113,\n",
       "           219,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1fa51d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.tokenization_utils_base.BatchEncoding"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f643284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize\n",
    "summary = model.generate(**tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "088d77d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  168,   117,  3632,   786,   120,   109, 13488, 11945,  1047,   108,\n",
       "           1093,   121, 13802,  1206,   108,  8123, 39471,   108,   111,  5030,\n",
       "            108,   154,  3837, 11913,  1267,   115,   909,   231,   127,   114,\n",
       "           1443,   711,   113,  4220,  1122,  4374,  1457,   124,   141,  4095,\n",
       "            131,   663,   113,  3359, 13405,   112,   109,  2918,   107,   325,\n",
       "            114,   177, 14842,   692,   124,  3837,  2354,   702,   115,  2774,\n",
       "            131,   116,  3266,   689,  4079,   120,   380,   131,   116,  3909,\n",
       "            218,   460,   154, 16434,   130,   126,  2138,   112,  1515,   107,\n",
       "            139,   692,   108,  8741,   380,   115,   110,   108, 12414,   109,\n",
       "          33375, 47207,  1093,   113,   109,   289,  8449,   604,   231,   108,\n",
       "            333,   109,   597, 17711, 73730,  4065,   108,   162,  1219,  5683,\n",
       "            244,   109, 22526,   113,   109, 23105,   107,   139,  4182,   374,\n",
       "            120,   333,   136,   908,   108, 21044,   115,   109,  2774,   131,\n",
       "            116,  2354,  1267,   114,  5946,   198, 44765,  9983,   496,   222,\n",
       "            176,   989,   108,   186,   195,   571,   154,  8309,   702,  1315,\n",
       "           5059,   113, 13488,  1122,  8309,   108,  4894,  1873,   112, 11371,\n",
       "            113,  1873,   113,   231,  1315,   197,  4814,   702,   107,   463,\n",
       "            131,   116,   154,   108,  8309,   702, 21415,   112,   129,   154,\n",
       "           3837,   108,   122,  1626,  9428,   115,  1972,   108,   197,  4814,\n",
       "            702,   107,   139,  2995,   416,   114,   433,  6024,   118,   136,\n",
       "           8309,  9983,   218,  5372,   115,   114,   198, 24086, 82296,  1298,\n",
       "            745, 15455,   114,  9419,  1393,   113,  8309,  1315,   118,  2468,\n",
       "            135, 31227,  8320,  3359, 13405,   190,   109,  2918,  1315,  3737,\n",
       "           6544,   164,   878,  7777,   111,  3568,  1994,   120,  2541,   219,\n",
       "          21044,   108,   964,   108,   124,  1077,   108,   112,   309,   154,\n",
       "           8309,   107, 21342,   108,   109,   320,  5221,   120,   136,  8309,\n",
       "           9983, 11623,   160,   371,   604,   231,   754,   108,   279,   109,\n",
       "            166,   173,  2003,  4651,   547,  7599,   115,   109,  3701, 35302,\n",
       "            107,   168,   131,   116, 10767,   180,  1298,   109,  2003,   148,\n",
       "            196,   124,   109,  2774,   131,   116,  1407,   112,  2354,  9428,\n",
       "            107,   343,   130,   380,   131,   116, 12546,  2003, 61574,   116,\n",
       "            108,   109,   177,   692,  4079,   120,   114, 33675,  1298,   218,\n",
       "           3951,   247,   115,   108,   111,   109,   711,   218,   129,   114,\n",
       "            701, 41269,   113,   883,   121, 18561,  1122,  8309,   107,   198,\n",
       "            159,  3701, 35302,   131,   116,  2003,  4651,   127, 25044,   108,\n",
       "            111,   256,  3744, 10966,   130,   114,   300,   121,  1704, 10687,\n",
       "            113,   883,  2332,   194,   649,   109,   692,   131,   116,   756,\n",
       "           1782, 80822, 33759, 74407,   144,   108,   114,  3177,   980,   115,\n",
       "          14842,   131,   116,  1318,   113,  2774,   108, 43847,   111, 55278,\n",
       "           5735,   107,   198,   822,   473,  4079,   120,   136,   218,   193,\n",
       "            109,  2774,   131,   116,  2354, 16521,   154, 13400,   112,  3837,\n",
       "            108,   300,   121,  1704,  1122,  8309,   702,   253,   130,   274,\n",
       "            684,   115,   109, 59057,   555,   496, 33759, 74407,   144,   131,\n",
       "            116,   692,  1229,   121, 13873,   117,  4767, 14390,  1121,   108,\n",
       "           4609,   113, 87896,   134, 14842,   108,   111,  1229,   121,  9489,\n",
       "            111,  1229,   121, 22655,   113, 14842,   131,   116, 80187,   900,\n",
       "            107,   321,   153,  1382,   108,   109,   320, 19470,   423,  8669,\n",
       "            113, 45163,  4510,  1355,   121, 13778,   129, 89221,   118,  1524,\n",
       "            386, 46934,  1315,   612,   121, 12052,   316, 14800,   120,   133,\n",
       "            174,   279,   118,  2490,   113,  3734,   113,   231,   111,  1843,\n",
       "            514, 14299,   127, 10303,   115, 45163,   107,   139,  5349,   113,\n",
       "            219,     1]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{**tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61561198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,   202,   177,   692,  4079,   120,   109,  2774,   131,   116,\n",
       "          2354,   218,   460,   154, 16434,   130,   126,  2138,   112,  1515,\n",
       "           107,     1]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary in tokens\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59a288f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<pad> A new study suggests that the Earth's climate may become more volatile as it continues to warm.</s>\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decode summary\n",
    "tokenizer.decode(summary[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
